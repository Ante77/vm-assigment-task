{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe21c03c-5464-4fca-8053-33c3c74978c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798da7e-11c1-4faf-829a-cd8368472fb9",
   "metadata": {},
   "source": [
    "Different LLMs from HuggingFace and vector store FAISS are used. Once the LLM is run using N randomly selected samples (with fixed seed), it is saved locally to data/vector_stores/and loaded for future use. Samples only need to be embedded once for each LLM x N combination.\n",
    "\n",
    "Outputs for each query are saved to data/output/ with an appropriate name (class name + suffix)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760e957e-6b48-4271-bc92-787bf406201d",
   "metadata": {},
   "source": [
    "QUERIES - queries we are interested in\n",
    "\n",
    "NUMBER OF ARTICLES - represents how many \"top results\" we want to output to Excel\n",
    "\n",
    "SAMPLE SIZE - represents the size of the random sample of blogs that represent our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b31306-e9de-4cc8-8ff7-32e4288e0d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directories set up.\n",
      "DataFrame loaded.\n",
      "NLTK prepared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Antisha\\anaconda3\\envs\\vm_task_env\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'QUERIES': [\n",
    "        \"What are people saying about relationships?\",\n",
    "        \"How do bloggers feel about technology advancements?\",\n",
    "        \"Tell me something about Brasil\",\n",
    "        \"car mechanics price\"\n",
    "    ],\n",
    "    'NUMBER OF ARTICLES': 3,\n",
    "    'SAMPLE SIZE': 25000\n",
    "}\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "vector_stores_dir = os.path.join(data_dir, 'vector_stores')\n",
    "embeddings_dir = os.path.join(data_dir, 'embeddings')\n",
    "sampled_data_dir = os.path.join(data_dir, 'sampled_data')\n",
    "output_dir = os.path.join(data_dir, 'output')\n",
    "\n",
    "os.makedirs(vector_stores_dir, exist_ok=True)\n",
    "os.makedirs(embeddings_dir, exist_ok=True)\n",
    "os.makedirs(sampled_data_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"Data directories set up.\")\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_dir, 'blogtext.csv'))\n",
    "\n",
    "print(\"DataFrame loaded.\")\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "print(\"NLTK prepared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "146092e2-eb25-4cb1-9bab-ba6f3b96669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentRetrievalSystem(ABC):\n",
    "    def __init__(self, df, sample_size=100000, random_state=42):\n",
    "        self.df = df\n",
    "        self.sample_size = sample_size\n",
    "        self.random_state = random_state\n",
    "        self.df_sampled = None\n",
    "        self.doc_list = None\n",
    "        self.split_docs = None\n",
    "        self.embedding_model = None\n",
    "        self.vector_store = None\n",
    "        self.vector_store_path = None\n",
    "\n",
    "        self.class_name = self.__class__.__name__\n",
    "        self.embedding_model_name = self.get_embedding_model_name()\n",
    "        self.vector_store_name = f\"{self.class_name}_{self.embedding_model_name}_{self.sample_size}\"\n",
    "    \n",
    "        self.data_dir = data_dir\n",
    "        self.vector_stores_dir = vector_stores_dir\n",
    "        self.embeddings_dir = embeddings_dir\n",
    "        self.sampled_data_dir = sampled_data_dir\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_embedding_model_name(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_embedding_model(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_text_splitter(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_vector_store_class(self):\n",
    "        pass\n",
    "\n",
    "    def prepare_data(self):\n",
    "        print(f\"Sampling {self.sample_size} rows from the DataFrame.\")\n",
    "        self.df_sampled = self.df.sample(n=self.sample_size, random_state=self.random_state)\n",
    "\n",
    "        sampled_data_path = os.path.join(self.sampled_data_dir, f\"{self.vector_store_name}_sampled_data.csv\")\n",
    "        self.df_sampled.to_csv(sampled_data_path, index=False)\n",
    "        print(f\"Sampled DataFrame saved as '{sampled_data_path}'.\")\n",
    "\n",
    "        self.df_sampled['text'] = self.df_sampled['text'].astype(str)\n",
    "\n",
    "        self.doc_list = []\n",
    "        for index, row in self.df_sampled.iterrows():\n",
    "            doc = Document(\n",
    "                page_content=row['text'],\n",
    "                metadata={\n",
    "                    'id': row['id'],\n",
    "                    'gender': row['gender'],\n",
    "                    'age': row['age'],\n",
    "                    'topic': row['topic'],\n",
    "                    'sign': row['sign'],\n",
    "                    'date': row['date']\n",
    "                }\n",
    "            )\n",
    "            self.doc_list.append(doc)\n",
    "        print(f\"Created {len(self.doc_list)} Document objects.\")\n",
    "\n",
    "        text_splitter = self.get_text_splitter()\n",
    "        self.split_docs = text_splitter.split_documents(self.doc_list)\n",
    "        print(f\"Split documents into {len(self.split_docs)} chunks.\")\n",
    "\n",
    "    def initialize_embeddings(self):\n",
    "        if self.embedding_model is None:\n",
    "            print(\"Initializing embedding model.\")\n",
    "            self.embedding_model = self.get_embedding_model()\n",
    "            print(f\"Initialized embedding model '{self.embedding_model_name}'.\")\n",
    "        else:\n",
    "            print(\"Embedding model already initialized.\")\n",
    "\n",
    "    def create_vector_store(self):\n",
    "        self.vector_store_path = os.path.join(self.vector_stores_dir, self.vector_store_name)\n",
    "    \n",
    "        if os.path.exists(self.vector_store_path):\n",
    "            print(f\"Loading existing vector store from '{self.vector_store_path}'.\")\n",
    "            self.vector_store = FAISS.load_local(\n",
    "                self.vector_store_path, embeddings=self.embedding_model, allow_dangerous_deserialization=True)\n",
    "            print(\"Vector store loaded.\")\n",
    "        else:\n",
    "            print(\"Creating new vector store from embeddings.\")\n",
    "    \n",
    "            os.makedirs(self.embeddings_dir, exist_ok=True)\n",
    "    \n",
    "            batch_size = 1000\n",
    "            all_embeddings = []\n",
    "            all_texts = []\n",
    "            all_metadatas = []\n",
    "    \n",
    "            print(\"Starting embedding process...\")\n",
    "            for i in range(0, len(self.split_docs), batch_size):\n",
    "                batch_docs = self.split_docs[i:i + batch_size]\n",
    "                batch_texts = [doc.page_content for doc in batch_docs]\n",
    "                batch_metadatas = [doc.metadata for doc in batch_docs]\n",
    "                batch_embeddings = self.embedding_model.embed_documents(batch_texts)\n",
    "                all_embeddings.extend(batch_embeddings)\n",
    "                all_texts.extend(batch_texts)\n",
    "                all_metadatas.extend(batch_metadatas)\n",
    "                print(f\"Processed batch {i // batch_size + 1}/{(len(self.split_docs) + batch_size - 1) // batch_size}\")\n",
    "    \n",
    "            print(f\"Completed embedding of {len(all_embeddings)} documents.\")\n",
    "    \n",
    "            self.vector_store = FAISS.from_texts(\n",
    "                texts=all_texts,\n",
    "                embedding=self.embedding_model,\n",
    "                metadatas=all_metadatas\n",
    "            )\n",
    "            print(\"Vector store created from texts.\")\n",
    "            self.vector_store.save_local(self.vector_store_path)\n",
    "            print(f\"Vector store saved to '{self.vector_store_path}'.\")\n",
    "\n",
    "\n",
    "    def get_top_n_documents(self, query, n):\n",
    "        if self.vector_store is None:\n",
    "            print(\"Vector store not initialized. Please run create_vector_store() first.\")\n",
    "            return []\n",
    "    \n",
    "        retriever = self.vector_store.as_retriever(search_kwargs={'k': n})\n",
    "    \n",
    "        docs_and_scores = self.vector_store.similarity_search_with_score(query, k=n)\n",
    "    \n",
    "        results = []\n",
    "        for doc, score in docs_and_scores:\n",
    "            result = {\n",
    "                'query': query,\n",
    "                'content': doc.page_content,\n",
    "                'metadata': doc.metadata,\n",
    "                'score': score\n",
    "            }\n",
    "            results.append(result)\n",
    "    \n",
    "        df_results = pd.DataFrame(results)\n",
    "    \n",
    "        output_file_name = f\"{self.vector_store_name}_results.xlsx\"\n",
    "        output_file_path = os.path.join(output_dir, output_file_name)\n",
    "    \n",
    "        if os.path.exists(output_file_path):\n",
    "            with pd.ExcelWriter(output_file_path, mode='a', if_sheet_exists='overlay') as writer:\n",
    "                if 'Sheet1' in writer.sheets:\n",
    "                    startrow = writer.sheets['Sheet1'].max_row\n",
    "                else:\n",
    "                    startrow = 0\n",
    "                df_results.to_excel(writer, index=False, header=False, startrow=startrow)\n",
    "        else:\n",
    "            df_results.to_excel(output_file_path, index=False)\n",
    "    \n",
    "        print(f\"Results saved to '{output_file_path}'.\")\n",
    "    \n",
    "        return results\n",
    "\n",
    "\n",
    "    def process_query(self, query, n):\n",
    "        results = self.get_top_n_documents(query, n)\n",
    "        if results:\n",
    "            top_result = results[0]\n",
    "            print(f\"\\nTop result from {self.class_name} for query '{query}':\")\n",
    "            print(\"Content:\", top_result['content'])\n",
    "            print(\"Metadata:\", top_result['metadata'])\n",
    "            print(\"Embedding Model (LLM):\", self.embedding_model_name)\n",
    "            print(\"-\" * 80)\n",
    "        else:\n",
    "            print(f\"No results found for query '{query}' using {self.class_name}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6d6f2e-6b9a-46e4-afea-db5d91fa8bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlogRetrievalSystemMiniLMFAISS(DocumentRetrievalSystem):\n",
    "    def get_embedding_model_name(self):\n",
    "        return 'all-MiniLM-L6-v2'\n",
    "\n",
    "    def get_embedding_model(self):\n",
    "        return HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "    def get_text_splitter(self):\n",
    "        return RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "    def get_vector_store_class(self):\n",
    "        from langchain.vectorstores import FAISS\n",
    "        return FAISS\n",
    "\n",
    "class BlogRetrievalSystemParaphraseFAISS(DocumentRetrievalSystem):\n",
    "    def get_embedding_model_name(self):\n",
    "        return 'paraphrase-MiniLM-L6-v2'\n",
    "\n",
    "    def get_embedding_model(self):\n",
    "        return HuggingFaceEmbeddings(model_name='sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    def get_text_splitter(self):\n",
    "        return RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "    def get_vector_store_class(self):\n",
    "        from langchain.vectorstores import FAISS\n",
    "        return FAISS\n",
    "\n",
    "\n",
    "class BlogRetrievalSystemMPNetFAISS(DocumentRetrievalSystem):\n",
    "    def get_embedding_model_name(self):\n",
    "        return 'all-mpnet-base-v2'\n",
    "    \n",
    "    def get_embedding_model(self):\n",
    "        return HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2')\n",
    "    \n",
    "    def get_text_splitter(self):\n",
    "        return RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    \n",
    "    def get_vector_store_class(self):\n",
    "        from langchain.vectorstores import FAISS\n",
    "        return FAISS\n",
    "\n",
    "class BlogRetrievalSystemQAFAISS(DocumentRetrievalSystem):\n",
    "    def get_embedding_model_name(self):\n",
    "        return 'multi-qa-mpnet-base-dot-v1'\n",
    "    \n",
    "    def get_embedding_model(self):\n",
    "        return HuggingFaceEmbeddings(model_name='sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "    \n",
    "    def get_text_splitter(self):\n",
    "        return RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    \n",
    "    def get_vector_store_class(self):\n",
    "        from langchain.vectorstores import FAISS\n",
    "        return FAISS\n",
    "\n",
    "class BlogRetrievalSystemMiniLMFAISS_NLTK(DocumentRetrievalSystem):\n",
    "    def get_embedding_model_name(self):\n",
    "        return 'all-MiniLM-L6-v2'\n",
    "\n",
    "    def get_embedding_model(self):\n",
    "        return HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "    def get_text_splitter(self):\n",
    "        from langchain.text_splitter import NLTKTextSplitter\n",
    "        return NLTKTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "    def get_vector_store_class(self):\n",
    "        from langchain.vectorstores import FAISS\n",
    "        return FAISS\n",
    "\n",
    "class BlogRetrievalSystemParaphraseFAISS_NLTK(DocumentRetrievalSystem):\n",
    "    def get_embedding_model_name(self):\n",
    "        return 'paraphrase-MiniLM-L6-v2'\n",
    "\n",
    "    def get_embedding_model(self):\n",
    "        return HuggingFaceEmbeddings(model_name='sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    def get_text_splitter(self):\n",
    "        from langchain.text_splitter import NLTKTextSplitter\n",
    "        return NLTKTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "    def get_vector_store_class(self):\n",
    "        from langchain.vectorstores import FAISS\n",
    "        return FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7787e7c5-7f11-4ca0-a434-318bd3f10080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing BlogRetrievalSystemMiniLMFAISS...\n",
      "Sampling 25000 rows from the DataFrame.\n",
      "Sampled DataFrame saved as 'C:\\Users\\Antisha\\Documents\\vm_task\\data\\sampled_data\\BlogRetrievalSystemMiniLMFAISS_all-MiniLM-L6-v2_25000_sampled_data.csv'.\n",
      "Created 25000 Document objects.\n",
      "Split documents into 45903 chunks.\n",
      "Initializing embedding model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antisha\\AppData\\Local\\Temp\\ipykernel_4876\\2115276612.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  return HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized embedding model 'all-MiniLM-L6-v2'.\n",
      "Loading existing vector store from 'C:\\Users\\Antisha\\Documents\\vm_task\\data\\vector_stores\\BlogRetrievalSystemMiniLMFAISS_all-MiniLM-L6-v2_25000'.\n",
      "Vector store loaded.\n",
      "\n",
      "Initializing BlogRetrievalSystemParaphraseFAISS...\n",
      "Sampling 25000 rows from the DataFrame.\n",
      "Sampled DataFrame saved as 'C:\\Users\\Antisha\\Documents\\vm_task\\data\\sampled_data\\BlogRetrievalSystemParaphraseFAISS_paraphrase-MiniLM-L6-v2_25000_sampled_data.csv'.\n",
      "Created 25000 Document objects.\n",
      "Split documents into 45903 chunks.\n",
      "Initializing embedding model.\n",
      "Initialized embedding model 'paraphrase-MiniLM-L6-v2'.\n",
      "Loading existing vector store from 'C:\\Users\\Antisha\\Documents\\vm_task\\data\\vector_stores\\BlogRetrievalSystemParaphraseFAISS_paraphrase-MiniLM-L6-v2_25000'.\n",
      "Vector store loaded.\n",
      "Results saved to 'C:\\Users\\Antisha\\Documents\\vm_task\\data\\output\\BlogRetrievalSystemMiniLMFAISS_all-MiniLM-L6-v2_25000_results.xlsx'.\n",
      "\n",
      "Top result from BlogRetrievalSystemMiniLMFAISS for query 'What are people saying about relationships?':\n",
      "Content: the two. It is a very personal thing talking about a relationship. Which brings up this question: Why are onlookers of long-term relationships very interested in the status, development and even interaction between the couple? For example, the annoying and very perverted question, 'What have you guys done?' I have seen asked a billion times of my friends... and they answer! Openly! About their physical relationship with another person completely uninvolved! I cannot answer that question! I will not! 'What have you guys done?' Why would anyone on earth ask something like that and actually expect an answer?! I am putting that one to rest. To anyone reading this, refrain from asking all couples of one week, one year, one decade or anyone for that matter what they have done with the opposite sex. It is a very personal thing to be discussing, and if they openly tell you because they trust in your closed-mouth response, good, but if you ask this question out of the blue, I do hope you will\n",
      "Metadata: {'id': 4024667, 'gender': 'female', 'age': 15, 'topic': 'indUnk', 'sign': 'Pisces', 'date': '25,July,2004'}\n",
      "Embedding Model (LLM): all-MiniLM-L6-v2\n",
      "--------------------------------------------------------------------------------\n",
      "Results saved to 'C:\\Users\\Antisha\\Documents\\vm_task\\data\\output\\BlogRetrievalSystemParaphraseFAISS_paraphrase-MiniLM-L6-v2_25000_results.xlsx'.\n",
      "\n",
      "Top result from BlogRetrievalSystemParaphraseFAISS for query 'What are people saying about relationships?':\n",
      "Content: so pessimistic toward realationships.  I just hear about negative things in relationships.  obviously.  good aspects of relationships aren't extolled in detail.  anyway, a few of my friends have got relationships, but in general, but relationships i hear about are not existant, shaky, depressing, or broken.  I've already got the effects of my parents breakon how i view a relationship to deal with in addition to that.  so it's all to say.  i just want to chill.  solo.  it'll take a hot dish to turn my head.  it can be done.  but now i'm happy with my status.  i had been waking up and first thing on my mind was to talk to God.  then this girl starting creeping into my mind.  i hated it.  it's something i can battle and all that, but i want as few distractions as posible.  i'm weak, but i want God at the top.  i can't handle women. they consume me.  not of my friend have jobs.  real ones anyway.  when do that start to happen? success.  what's that mean?  it could be fame.  but look at\n",
      "Metadata: {'id': 1216517, 'gender': 'male', 'age': 24, 'topic': 'Education', 'sign': 'Leo', 'date': '22,May,2004'}\n",
      "Embedding Model (LLM): paraphrase-MiniLM-L6-v2\n",
      "--------------------------------------------------------------------------------\n",
      "Results saved to 'C:\\Users\\Antisha\\Documents\\vm_task\\data\\output\\BlogRetrievalSystemMiniLMFAISS_all-MiniLM-L6-v2_25000_results.xlsx'.\n",
      "\n",
      "Top result from BlogRetrievalSystemMiniLMFAISS for query 'How do bloggers feel about technology advancements?':\n",
      "Content: I guess blogs are the new thing, and I&nbsp;don't want to be left out, so here's my attempt at keeping up with technology.\n",
      "Metadata: {'id': 4065478, 'gender': 'female', 'age': 25, 'topic': 'indUnk', 'sign': 'Taurus', 'date': '28,July,2004'}\n",
      "Embedding Model (LLM): all-MiniLM-L6-v2\n",
      "--------------------------------------------------------------------------------\n",
      "Results saved to 'C:\\Users\\Antisha\\Documents\\vm_task\\data\\output\\BlogRetrievalSystemParaphraseFAISS_paraphrase-MiniLM-L6-v2_25000_results.xlsx'.\n",
      "\n",
      "Top result from BlogRetrievalSystemParaphraseFAISS for query 'How do bloggers feel about technology advancements?':\n",
      "Content: BLOGGER  offers 4 ready-to-go blog formats so you don't have to catch up on twenty years of web technology (you stupid ape).  While they may be boring templates, they'll do the job.  There is nothing worse than finding a blog which has graphics and terrible colors strewn about so you don't know where to go.  It may look cool...but pisses me off.  Your reader shouldn't feel attacked by your design.  And once again, just because your friends say it's cool, doesn't mean it is.  Your friends could be tasteless-dumbasses like yourself.  That's the lesson for today.  Image is everything.   Next Lesson:   For Christ's sakeproofread!\n",
      "Metadata: {'id': 106651, 'gender': 'male', 'age': 25, 'topic': 'indUnk', 'sign': 'Leo', 'date': '01,June,2004'}\n",
      "Embedding Model (LLM): paraphrase-MiniLM-L6-v2\n",
      "--------------------------------------------------------------------------------\n",
      "Results saved to 'C:\\Users\\Antisha\\Documents\\vm_task\\data\\output\\BlogRetrievalSystemMiniLMFAISS_all-MiniLM-L6-v2_25000_results.xlsx'.\n",
      "\n",
      "Top result from BlogRetrievalSystemMiniLMFAISS for query 'Tell me something about Brasil':\n",
      "Content: hello from tom and andy!  Brazil Rocks!  Hey everyone, this is a e-postcard!  Brazil is sooo cool, see you all soon, good luck with your results!  Bye\n",
      "Metadata: {'id': 988941, 'gender': 'female', 'age': 17, 'topic': 'Student', 'sign': 'Capricorn', 'date': '04,August,2004'}\n",
      "Embedding Model (LLM): all-MiniLM-L6-v2\n",
      "--------------------------------------------------------------------------------\n",
      "Results saved to 'C:\\Users\\Antisha\\Documents\\vm_task\\data\\output\\BlogRetrievalSystemParaphraseFAISS_paraphrase-MiniLM-L6-v2_25000_results.xlsx'.\n",
      "\n",
      "Top result from BlogRetrievalSystemParaphraseFAISS for query 'Tell me something about Brasil':\n",
      "Content: hello from tom and andy!  Brazil Rocks!  Hey everyone, this is a e-postcard!  Brazil is sooo cool, see you all soon, good luck with your results!  Bye\n",
      "Metadata: {'id': 988941, 'gender': 'female', 'age': 17, 'topic': 'Student', 'sign': 'Capricorn', 'date': '04,August,2004'}\n",
      "Embedding Model (LLM): paraphrase-MiniLM-L6-v2\n",
      "--------------------------------------------------------------------------------\n",
      "Results saved to 'C:\\Users\\Antisha\\Documents\\vm_task\\data\\output\\BlogRetrievalSystemMiniLMFAISS_all-MiniLM-L6-v2_25000_results.xlsx'.\n",
      "\n",
      "Top result from BlogRetrievalSystemMiniLMFAISS for query 'car mechanics price':\n",
      "Content: I can't believe how expensive some of these cars are.  More and more it seems like you pay for name recognition rather than actual performance or features.  I need to narrow my search down to something with great mileage, I'm tired of paying $20+ a week to fill up my truck.  I also want something with a manual transmission.  I miss the fun of shifting from back in high school with the little red mazda pickup.  No clue how long the search will continue, will touch on the subject again when I have the field narrowed down to only a few vehicles.\n",
      "Metadata: {'id': 4177236, 'gender': 'male', 'age': 24, 'topic': 'Sports-Recreation', 'sign': 'Aquarius', 'date': '09,August,2004'}\n",
      "Embedding Model (LLM): all-MiniLM-L6-v2\n",
      "--------------------------------------------------------------------------------\n",
      "Results saved to 'C:\\Users\\Antisha\\Documents\\vm_task\\data\\output\\BlogRetrievalSystemParaphraseFAISS_paraphrase-MiniLM-L6-v2_25000_results.xlsx'.\n",
      "\n",
      "Top result from BlogRetrievalSystemParaphraseFAISS for query 'car mechanics price':\n",
      "Content: I hate car buying   Well, as if I needed a reminder of why I hate car-buying, I got one today.  Seems that the car I was looking at (an '04 Accent) suddenly increased in price from $6495 to $6995; they claim that the $6495 car has already been sold, and that as this was a special discount price, the next discounted '04 is going for $6995 (nonnegotiable).  I honestly don't know if this is true or not; my dad thinks that they are pulling a 'bait-and-switch.'  Of course, me being the naive, trusting person that I am...well, I want to believe them, and I honestly still think that it's an ok deal even at $6995.  Unfortunately, I'm trying to keep the total debt for this transaction below $7,000, so $6995 doesn't cut it (adding taxes and everything else brings the total to about $7500).  Grr...and I really liked that car.  Oh well...back to looking at mid-mileage Toyotas and whatnot.  GRRR....looks like I'm back to square one.\n",
      "Metadata: {'id': 2155463, 'gender': 'male', 'age': 23, 'topic': 'Student', 'sign': 'Sagittarius', 'date': '16,November,2003'}\n",
      "Embedding Model (LLM): paraphrase-MiniLM-L6-v2\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "subclasses = [\n",
    "    BlogRetrievalSystemMiniLMFAISS,\n",
    "    BlogRetrievalSystemParaphraseFAISS,\n",
    "    # BlogRetrievalSystemMPNetFAISS,\n",
    "    # BlogRetrievalSystemQAFAISS,\n",
    "    # BlogRetrievalSystemMiniLMFAISS_NLTK,\n",
    "    # BlogRetrievalSystemParaphraseFAISS_NLTK,\n",
    "]\n",
    "\n",
    "instances = []\n",
    "for subclass in subclasses:\n",
    "    print(f\"\\nInitializing {subclass.__name__}...\")\n",
    "    blog_system = subclass(df, sample_size=config['SAMPLE SIZE'])\n",
    "    blog_system.prepare_data()\n",
    "    blog_system.initialize_embeddings()\n",
    "    blog_system.create_vector_store()\n",
    "    instances.append(blog_system)\n",
    "\n",
    "for query in config['QUERIES']:\n",
    "    for blog_system in instances:\n",
    "        blog_system.process_query(query, config['NUMBER OF ARTICLES'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49053a-50a3-429d-b66a-12fbc0726bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
